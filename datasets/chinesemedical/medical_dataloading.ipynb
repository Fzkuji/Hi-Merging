{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T11:22:14.221953Z",
     "start_time": "2024-12-13T11:22:00.640485Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "# Alpaca 格式转换函数\n",
    "def convert_to_alpaca_format(dataset):\n",
    "    alpaca_dataset = []\n",
    "    for data in dataset:\n",
    "        # 假设数据集中有'instruction', 'input', 'output'字段，根据实际数据集调整字段名称\n",
    "        alpaca_data = {\n",
    "            \"instruction\": data.get('instruction', \"\"),\n",
    "            \"input\": data.get('query', \"\"),\n",
    "            \"output\": data.get('response', \"\")\n",
    "        }\n",
    "        alpaca_dataset.append(alpaca_data)\n",
    "    return alpaca_dataset\n",
    "\n",
    "# 保存数据集到 JSON 文件\n",
    "def save_dataset(dataset, save_path):\n",
    "    if not os.path.exists(os.path.dirname(save_path)):\n",
    "        os.makedirs(os.path.dirname(save_path))\n",
    "    with open(save_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(dataset, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "# 主程序：遍历数据集并保存\n",
    "save_path = \"./data/llama-factory\"\n",
    "\n",
    "# 遍历医疗数据集\n",
    "try:\n",
    "    # 加载完整数据集\n",
    "    dataset = load_dataset(\n",
    "        \"michaelwzhu/ChatMed_Consult_Dataset\",\n",
    "        # data_files={\"train\": f\"{benchmark}/train-*.parquet\"},\n",
    "        split=\"train\"\n",
    "    )\n",
    "\n",
    "    # 切分数据集为 90% 训练集和 10% 测试+验证集\n",
    "    train_testvalid = dataset.train_test_split(test_size=0.1)\n",
    "\n",
    "    # 将测试+验证集切分为 50% 测试集和 50% 验证集\n",
    "    test_valid = train_testvalid['test'].train_test_split(test_size=0.5)\n",
    "\n",
    "    # 合并为一个 DatasetDict\n",
    "    train_test_valid_dataset = DatasetDict({\n",
    "        'train': train_testvalid['train'],\n",
    "        'test': test_valid['test'],\n",
    "        'valid': test_valid['train']\n",
    "    })\n",
    "\n",
    "    # 转换为 Alpaca 格式并保存\n",
    "    train_alpaca_dataset = convert_to_alpaca_format(train_test_valid_dataset['train'])\n",
    "    test_alpaca_dataset = convert_to_alpaca_format(train_test_valid_dataset['test'])\n",
    "    valid_alpaca_dataset = convert_to_alpaca_format(train_test_valid_dataset['valid'])\n",
    "\n",
    "    # save_dataset(train_alpaca_dataset, f\"{save_path}/Medical/{benchmark}_train.json\")\n",
    "    save_dataset(test_alpaca_dataset, f\"{save_path}/ChatMed_Consult_Dataset_test.json\")\n",
    "    # save_dataset(valid_alpaca_dataset, f\"{save_path}/Medical/{benchmark}_valid.json\")\n",
    "\n",
    "    print(f\"Saved Medical benchmark ChatMed_Consult_Dataset train, test, and valid sets to Alpaca format.\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to process Medical benchmark ChatMed_Consult_Dataset: {e}\")\n"
   ],
   "id": "af7a74a605eff75f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Medical benchmark ChatMed_Consult_Dataset train, test, and valid sets to Alpaca format.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T11:37:10.971146Z",
     "start_time": "2024-12-13T11:36:57.144600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "# Alpaca 格式转换函数\n",
    "def convert_to_alpaca_format(dataset):\n",
    "    alpaca_dataset = []\n",
    "    for data in dataset:\n",
    "        # 假设数据集中有'instruction', 'input', 'output'字段，根据实际数据集调整字段名称\n",
    "        alpaca_data = {\n",
    "            \"instruction\": data.get('a', \"\"),\n",
    "            \"input\": data.get('instruction', \"\"),\n",
    "            \"output\": data.get('output', \"\")\n",
    "        }\n",
    "        alpaca_dataset.append(alpaca_data)\n",
    "    return alpaca_dataset\n",
    "\n",
    "# 保存数据集到 JSON 文件\n",
    "def save_dataset(dataset, save_path):\n",
    "    if not os.path.exists(os.path.dirname(save_path)):\n",
    "        os.makedirs(os.path.dirname(save_path))\n",
    "    with open(save_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(dataset, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "# 主程序：遍历数据集并保存\n",
    "save_path = \"./data/llama-factory\"\n",
    "\n",
    "# 遍历医疗数据集\n",
    "try:\n",
    "    # 加载完整数据集\n",
    "    dataset = load_dataset(\n",
    "        \"tyang816/MedChatZH\",\n",
    "        # data_files={\"train\": f\"{benchmark}/train-*.parquet\"},\n",
    "        # split=\"validation\"\n",
    "    )\n",
    "\n",
    "    # 转换为 Alpaca 格式并保存\n",
    "    train_alpaca_dataset = convert_to_alpaca_format(dataset['train'])\n",
    "    # test_alpaca_dataset = convert_to_alpaca_format(train_test_valid_dataset['test'])\n",
    "    valid_alpaca_dataset = convert_to_alpaca_format(dataset['validation'])\n",
    "\n",
    "    # save_dataset(train_alpaca_dataset, f\"{save_path}/Medical/{benchmark}_train.json\")\n",
    "    save_dataset(valid_alpaca_dataset, f\"{save_path}/MedChatZH_test.json\")\n",
    "    # save_dataset(valid_alpaca_dataset, f\"{save_path}/Medical/{benchmark}_valid.json\")\n",
    "\n",
    "    print(f\"Saved Medical benchmark ChatMed_Consult_Dataset train, test, and valid sets to Alpaca format.\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to process Medical benchmark ChatMed_Consult_Dataset: {e}\")\n"
   ],
   "id": "3043470c5ce17c60",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Medical benchmark ChatMed_Consult_Dataset train, test, and valid sets to Alpaca format.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c290abd8b14355c2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
